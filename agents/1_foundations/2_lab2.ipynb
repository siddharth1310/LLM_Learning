{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Second Lab - Week 1, Day 3\n",
    "\n",
    "Today we will work with lots of models! This is a way to get comfortable with APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Important point - please read</h2>\n",
    "            <span style=\"color:#ff7800;\">The way I collaborate with you may be different to other courses you've taken. I prefer not to type code while you watch. Rather, I execute Jupyter Labs, like this, and give you an intuition for what's going on. My suggestion is that you carefully execute this yourself, <b>after</b> watching the lecture. Add print statements to understand what's going on, and then come up with your own variations.<br/><br/>If you have time, I'd love it if you submit a PR for changes in the community_contributions folder - instructions in the resources. Also, if you have a Github account, use this to showcase your variations. Not only is this essential practice, but it demonstrates your skills to others, including perhaps future clients or employers...\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with imports - ask ChatGPT to explain any package that you don't know\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Always remember to do this!\n",
    "load_dotenv(override = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key not set (and this is optional)\n",
      "Google API Key not set (and this is optional)\n",
      "DeepSeek API Key not set (and this is optional)\n",
      "Groq API Key not set (and this is optional)\n"
     ]
    }
   ],
   "source": [
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "deepseek_api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set (and this is optional)\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"Groq API Key exists and begins {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Groq API Key not set (and this is optional)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "request = request + \"Answer only with the question, no explanation.\"\n",
    "messages = [{\"role\" : \"user\", \"content\" : request}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. Answer only with the question, no explanation.'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the ethical implications of employing artificial intelligence in decision-making processes that affect human lives, and how can we ensure accountability in such systems?\n"
     ]
    }
   ],
   "source": [
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(model = \"gpt-4o-mini\", messages = messages)\n",
    "question = response.choices[0].message.content\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors = []\n",
    "answers = []\n",
    "messages = [{\"role\" : \"user\", \"content\" : question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The deployment of artificial intelligence (AI) in decision-making processes that affect human lives raises several ethical implications and concerns. These issues span multiple domains, including fairness, transparency, accountability, and privacy. Here are the key ethical implications and ways to ensure accountability:\n",
       "\n",
       "### Ethical Implications:\n",
       "\n",
       "1. **Bias and Discrimination**:\n",
       "   - AI systems can perpetuate or exacerbate biases present in training data. This can lead to unfair treatment or discrimination against specific groups, particularly marginalized communities.\n",
       "   - **Implication**: Disparate impacts could result in inequalities in areas like hiring, lending, law enforcement, and healthcare.\n",
       "\n",
       "2. **Transparency and Explainability**:\n",
       "   - Many AI systems, particularly those using complex algorithms, operate as \"black boxes,\" making it difficult to understand their decision-making processes.\n",
       "   - **Implication**: Lack of transparency can erode trust and make it challenging for affected individuals to understand and challenge decisions made about them.\n",
       "\n",
       "3. **Accountability and Responsibility**:\n",
       "   - When AI systems make decisions, it can be unclear who is responsible for outcomes, especially if those outcomes are harmful.\n",
       "   - **Implication**: This ambiguity can evade critical scrutiny and diminish the accountability of organizations deploying AI.\n",
       "\n",
       "4. **Privacy Concerns**:\n",
       "   - The use of AI often entails collecting and processing large amounts of personal data, raising concerns about privacy and consent.\n",
       "   - **Implication**: People may not have a clear understanding of how their data is used, leading to potential misuse or unauthorized access to personal information.\n",
       "\n",
       "5. **Informed Consent**:\n",
       "   - In contexts like healthcare, patients must be adequately informed about how AI will be used in their treatment decisions, including possible risks and benefits.\n",
       "   - **Implication**: Failure to ensure informed consent undermines ethical principles of autonomy and respect for individuals.\n",
       "\n",
       "6. **Autonomy**:\n",
       "   - AI systems can influence decisions in ways that may reduce human agency, as individuals might rely overly on automated recommendations.\n",
       "   - **Implication**: This can lead to a loss of personal responsibility or critical thinking regarding important life decisions.\n",
       "\n",
       "### Ensuring Accountability:\n",
       "\n",
       "1. **Regulatory Frameworks**:\n",
       "   - Establish laws and guidelines that govern the use of AI in critical decision-making areas. These should address ethical use, data protection, and accountability for outcomes.\n",
       "\n",
       "2. **Transparency Requirements**:\n",
       "   - Mandate that organizations provide clear, accessible information about how AI systems operate, including the data they use and how decisions are made.\n",
       "\n",
       "3. **Bias Mitigation Strategies**:\n",
       "   - Implement regular audits of AI systems to identify and rectify biases. This should include diverse training datasets and inclusive design practices to ensure fairness.\n",
       "\n",
       "4. **Human Oversight**:\n",
       "   - Maintain human-in-the-loop mechanisms where human judgment is involved in decision-making processes, especially in high-stakes scenarios such as criminal justice or medical diagnosis.\n",
       "\n",
       "5. **Clear Accountability Structures**:\n",
       "   - Define clear lines of accountability for AI-related decisions, ensuring that both developers and users of AI systems are responsible for the impacts of those systems.\n",
       "\n",
       "6. **Public Engagement and Stakeholder Involvement**:\n",
       "   - Involve diverse stakeholders, including impacted communities, in the design and implementation of AI systems to ensure that various perspectives are considered.\n",
       "\n",
       "7. **Ethical AI Frameworks**:\n",
       "   - Encourage the adoption of ethical frameworks by organizations that use AI, guiding their practices in alignment with social values and human rights.\n",
       "\n",
       "8. **Ongoing Education and Awareness**:\n",
       "   - Facilitate ongoing training for developers and users about the ethical implications of AI, emphasizing the importance of accountability and responsible usage.\n",
       "\n",
       "By attending to these ethical considerations and implementing strategies for accountability, we can strive to harness the benefits of AI while mitigating its risks and ensuring that it serves humanity equitably and responsibly."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The API we know well\n",
    "\n",
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "response = openai.chat.completions.create(model = model_name, messages = messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anthropic has a slightly different API, and Max Tokens is required\n",
    "\n",
    "model_name = \"claude-3-7-sonnet-latest\"\n",
    "\n",
    "claude = Anthropic()\n",
    "response = claude.messages.create(model = model_name, messages = messages, max_tokens = 1000)\n",
    "answer = response.content[0].text\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini = OpenAI(api_key = google_api_key, base_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "model_name = \"gemini-2.0-flash\"\n",
    "\n",
    "response = gemini.chat.completions.create(model = model_name, messages = messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek = OpenAI(api_key = deepseek_api_key, base_url = \"https://api.deepseek.com/v1\")\n",
    "model_name = \"deepseek-chat\"\n",
    "\n",
    "response = deepseek.chat.completions.create(model = model_name, messages = messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq = OpenAI(api_key = groq_api_key, base_url = \"https://api.groq.com/openai/v1\")\n",
    "model_name = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "response = groq.chat.completions.create(model = model_name, messages = messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the next cell, we will use Ollama\n",
    "\n",
    "Ollama runs a local web service that gives an OpenAI compatible endpoint,  \n",
    "and runs models locally using high performance C++ code.\n",
    "\n",
    "If you don't have Ollama, install it here by visiting https://ollama.com then pressing Download and following the instructions.\n",
    "\n",
    "After it's installed, you should be able to visit here: http://localhost:11434 and see the message \"Ollama is running\"\n",
    "\n",
    "You might need to restart Cursor (and maybe reboot). Then open a Terminal (control+\\`) and run `ollama serve`\n",
    "\n",
    "Useful Ollama commands (run these in the terminal, or with an exclamation mark in this notebook):\n",
    "\n",
    "`ollama pull <model_name>` downloads a model locally  \n",
    "`ollama ls` lists all the models you've downloaded  \n",
    "`ollama rm <model_name>` deletes the specified model from your downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Super important - ignore me at your peril!</h2>\n",
    "            <span style=\"color:#ff7800;\">The model called <b>llama3.3</b> is FAR too large for home computers - it's not intended for personal computing and will consume all your resources! Stick with the nicely sized <b>llama3.2</b> or <b>llama3.2:1b</b> and if you want larger, try llama3.1 or smaller variants of Qwen, Gemma, Phi or DeepSeek. See the <A href=\"https://ollama.com/models\">the Ollama models page</a> for a full list of models and sizes.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The increasing use of artificial intelligence (AI) in decision-making processes that affect human lives raises significant ethical concerns. Some of the key implications include:\n",
       "\n",
       "1. Bias and discrimination: AI systems can perpetuate existing biases and discriminatory practices if they are trained on biased data or designed with biased algorithms.\n",
       "2. Lack of transparency: Complex AI systems can be difficult to understand, making it challenging to identify mistakes or biases in decision-making processes.\n",
       "3. Autonomy and agency: As AI assumes more decision-making roles, there is a risk that humans may lose control over their own lives and decisions.\n",
       "4. Accountability: With AI involved in decision-making processes, it can be unclear who is responsible for errors or harm caused by those decisions.\n",
       "5. Value alignment: AI systems may not share human values, leading to decisions that are morally questionable.\n",
       "\n",
       "To ensure accountability in AI-based decision-making systems, consider the following measures:\n",
       "\n",
       "1. **Transparency and explainability**: Design AI systems that provide clear explanations for their decisions and actions, enabling humans to understand the reasoning behind those decisions.\n",
       "2. **Data quality and validation**: Ensure that training data is diverse"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ollama = OpenAI(base_url = \"http://localhost:11434/v1\", \n",
    "                api_key = \"ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIPezsN01coZZKU862cpimvmOE2lal8PwS4IDI9Jht7Hj ollama_local\")\n",
    "\n",
    "model_name = \"llama3.2\"\n",
    "\n",
    "response = ollama.chat.completions.create(model = model_name, messages = messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt-4o-mini', 'llama3.2']\n",
      "['The deployment of artificial intelligence (AI) in decision-making processes that affect human lives raises several ethical implications and concerns. These issues span multiple domains, including fairness, transparency, accountability, and privacy. Here are the key ethical implications and ways to ensure accountability:\\n\\n### Ethical Implications:\\n\\n1. **Bias and Discrimination**:\\n   - AI systems can perpetuate or exacerbate biases present in training data. This can lead to unfair treatment or discrimination against specific groups, particularly marginalized communities.\\n   - **Implication**: Disparate impacts could result in inequalities in areas like hiring, lending, law enforcement, and healthcare.\\n\\n2. **Transparency and Explainability**:\\n   - Many AI systems, particularly those using complex algorithms, operate as \"black boxes,\" making it difficult to understand their decision-making processes.\\n   - **Implication**: Lack of transparency can erode trust and make it challenging for affected individuals to understand and challenge decisions made about them.\\n\\n3. **Accountability and Responsibility**:\\n   - When AI systems make decisions, it can be unclear who is responsible for outcomes, especially if those outcomes are harmful.\\n   - **Implication**: This ambiguity can evade critical scrutiny and diminish the accountability of organizations deploying AI.\\n\\n4. **Privacy Concerns**:\\n   - The use of AI often entails collecting and processing large amounts of personal data, raising concerns about privacy and consent.\\n   - **Implication**: People may not have a clear understanding of how their data is used, leading to potential misuse or unauthorized access to personal information.\\n\\n5. **Informed Consent**:\\n   - In contexts like healthcare, patients must be adequately informed about how AI will be used in their treatment decisions, including possible risks and benefits.\\n   - **Implication**: Failure to ensure informed consent undermines ethical principles of autonomy and respect for individuals.\\n\\n6. **Autonomy**:\\n   - AI systems can influence decisions in ways that may reduce human agency, as individuals might rely overly on automated recommendations.\\n   - **Implication**: This can lead to a loss of personal responsibility or critical thinking regarding important life decisions.\\n\\n### Ensuring Accountability:\\n\\n1. **Regulatory Frameworks**:\\n   - Establish laws and guidelines that govern the use of AI in critical decision-making areas. These should address ethical use, data protection, and accountability for outcomes.\\n\\n2. **Transparency Requirements**:\\n   - Mandate that organizations provide clear, accessible information about how AI systems operate, including the data they use and how decisions are made.\\n\\n3. **Bias Mitigation Strategies**:\\n   - Implement regular audits of AI systems to identify and rectify biases. This should include diverse training datasets and inclusive design practices to ensure fairness.\\n\\n4. **Human Oversight**:\\n   - Maintain human-in-the-loop mechanisms where human judgment is involved in decision-making processes, especially in high-stakes scenarios such as criminal justice or medical diagnosis.\\n\\n5. **Clear Accountability Structures**:\\n   - Define clear lines of accountability for AI-related decisions, ensuring that both developers and users of AI systems are responsible for the impacts of those systems.\\n\\n6. **Public Engagement and Stakeholder Involvement**:\\n   - Involve diverse stakeholders, including impacted communities, in the design and implementation of AI systems to ensure that various perspectives are considered.\\n\\n7. **Ethical AI Frameworks**:\\n   - Encourage the adoption of ethical frameworks by organizations that use AI, guiding their practices in alignment with social values and human rights.\\n\\n8. **Ongoing Education and Awareness**:\\n   - Facilitate ongoing training for developers and users about the ethical implications of AI, emphasizing the importance of accountability and responsible usage.\\n\\nBy attending to these ethical considerations and implementing strategies for accountability, we can strive to harness the benefits of AI while mitigating its risks and ensuring that it serves humanity equitably and responsibly.', 'The increasing use of artificial intelligence (AI) in decision-making processes that affect human lives raises significant ethical concerns. Some of the key implications include:\\n\\n1. Bias and discrimination: AI systems can perpetuate existing biases and discriminatory practices if they are trained on biased data or designed with biased algorithms.\\n2. Lack of transparency: Complex AI systems can be difficult to understand, making it challenging to identify mistakes or biases in decision-making processes.\\n3. Autonomy and agency: As AI assumes more decision-making roles, there is a risk that humans may lose control over their own lives and decisions.\\n4. Accountability: With AI involved in decision-making processes, it can be unclear who is responsible for errors or harm caused by those decisions.\\n5. Value alignment: AI systems may not share human values, leading to decisions that are morally questionable.\\n\\nTo ensure accountability in AI-based decision-making systems, consider the following measures:\\n\\n1. **Transparency and explainability**: Design AI systems that provide clear explanations for their decisions and actions, enabling humans to understand the reasoning behind those decisions.\\n2. **Data quality and validation**: Ensure that training data is diverse']\n"
     ]
    }
   ],
   "source": [
    "# So where are we?\n",
    "\n",
    "print(competitors)\n",
    "print(answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Competitor : gpt-4o-mini\n",
      "\n",
      "The deployment of artificial intelligence (AI) in decision-making processes that affect human lives raises several ethical implications and concerns. These issues span multiple domains, including fairness, transparency, accountability, and privacy. Here are the key ethical implications and ways to ensure accountability:\n",
      "\n",
      "### Ethical Implications:\n",
      "\n",
      "1. **Bias and Discrimination**:\n",
      "   - AI systems can perpetuate or exacerbate biases present in training data. This can lead to unfair treatment or discrimination against specific groups, particularly marginalized communities.\n",
      "   - **Implication**: Disparate impacts could result in inequalities in areas like hiring, lending, law enforcement, and healthcare.\n",
      "\n",
      "2. **Transparency and Explainability**:\n",
      "   - Many AI systems, particularly those using complex algorithms, operate as \"black boxes,\" making it difficult to understand their decision-making processes.\n",
      "   - **Implication**: Lack of transparency can erode trust and make it challenging for affected individuals to understand and challenge decisions made about them.\n",
      "\n",
      "3. **Accountability and Responsibility**:\n",
      "   - When AI systems make decisions, it can be unclear who is responsible for outcomes, especially if those outcomes are harmful.\n",
      "   - **Implication**: This ambiguity can evade critical scrutiny and diminish the accountability of organizations deploying AI.\n",
      "\n",
      "4. **Privacy Concerns**:\n",
      "   - The use of AI often entails collecting and processing large amounts of personal data, raising concerns about privacy and consent.\n",
      "   - **Implication**: People may not have a clear understanding of how their data is used, leading to potential misuse or unauthorized access to personal information.\n",
      "\n",
      "5. **Informed Consent**:\n",
      "   - In contexts like healthcare, patients must be adequately informed about how AI will be used in their treatment decisions, including possible risks and benefits.\n",
      "   - **Implication**: Failure to ensure informed consent undermines ethical principles of autonomy and respect for individuals.\n",
      "\n",
      "6. **Autonomy**:\n",
      "   - AI systems can influence decisions in ways that may reduce human agency, as individuals might rely overly on automated recommendations.\n",
      "   - **Implication**: This can lead to a loss of personal responsibility or critical thinking regarding important life decisions.\n",
      "\n",
      "### Ensuring Accountability:\n",
      "\n",
      "1. **Regulatory Frameworks**:\n",
      "   - Establish laws and guidelines that govern the use of AI in critical decision-making areas. These should address ethical use, data protection, and accountability for outcomes.\n",
      "\n",
      "2. **Transparency Requirements**:\n",
      "   - Mandate that organizations provide clear, accessible information about how AI systems operate, including the data they use and how decisions are made.\n",
      "\n",
      "3. **Bias Mitigation Strategies**:\n",
      "   - Implement regular audits of AI systems to identify and rectify biases. This should include diverse training datasets and inclusive design practices to ensure fairness.\n",
      "\n",
      "4. **Human Oversight**:\n",
      "   - Maintain human-in-the-loop mechanisms where human judgment is involved in decision-making processes, especially in high-stakes scenarios such as criminal justice or medical diagnosis.\n",
      "\n",
      "5. **Clear Accountability Structures**:\n",
      "   - Define clear lines of accountability for AI-related decisions, ensuring that both developers and users of AI systems are responsible for the impacts of those systems.\n",
      "\n",
      "6. **Public Engagement and Stakeholder Involvement**:\n",
      "   - Involve diverse stakeholders, including impacted communities, in the design and implementation of AI systems to ensure that various perspectives are considered.\n",
      "\n",
      "7. **Ethical AI Frameworks**:\n",
      "   - Encourage the adoption of ethical frameworks by organizations that use AI, guiding their practices in alignment with social values and human rights.\n",
      "\n",
      "8. **Ongoing Education and Awareness**:\n",
      "   - Facilitate ongoing training for developers and users about the ethical implications of AI, emphasizing the importance of accountability and responsible usage.\n",
      "\n",
      "By attending to these ethical considerations and implementing strategies for accountability, we can strive to harness the benefits of AI while mitigating its risks and ensuring that it serves humanity equitably and responsibly.\n",
      "Competitor : llama3.2\n",
      "\n",
      "The increasing use of artificial intelligence (AI) in decision-making processes that affect human lives raises significant ethical concerns. Some of the key implications include:\n",
      "\n",
      "1. Bias and discrimination: AI systems can perpetuate existing biases and discriminatory practices if they are trained on biased data or designed with biased algorithms.\n",
      "2. Lack of transparency: Complex AI systems can be difficult to understand, making it challenging to identify mistakes or biases in decision-making processes.\n",
      "3. Autonomy and agency: As AI assumes more decision-making roles, there is a risk that humans may lose control over their own lives and decisions.\n",
      "4. Accountability: With AI involved in decision-making processes, it can be unclear who is responsible for errors or harm caused by those decisions.\n",
      "5. Value alignment: AI systems may not share human values, leading to decisions that are morally questionable.\n",
      "\n",
      "To ensure accountability in AI-based decision-making systems, consider the following measures:\n",
      "\n",
      "1. **Transparency and explainability**: Design AI systems that provide clear explanations for their decisions and actions, enabling humans to understand the reasoning behind those decisions.\n",
      "2. **Data quality and validation**: Ensure that training data is diverse\n"
     ]
    }
   ],
   "source": [
    "# It's nice to know how to use \"zip\"\n",
    "for competitor, answer in zip(competitors, answers):\n",
    "    print(f\"Competitor : {competitor}\\n\\n{answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's bring this together - note the use of \"enumerate\"\n",
    "\n",
    "together = \"\"\n",
    "for index, answer in enumerate(answers):\n",
    "    together = together + f\"# Response from competitor {index + 1}\\n\\n\"\n",
    "    together = together + answer + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Response from competitor 1\n",
      "\n",
      "The deployment of artificial intelligence (AI) in decision-making processes that affect human lives raises several ethical implications and concerns. These issues span multiple domains, including fairness, transparency, accountability, and privacy. Here are the key ethical implications and ways to ensure accountability:\n",
      "\n",
      "### Ethical Implications:\n",
      "\n",
      "1. **Bias and Discrimination**:\n",
      "   - AI systems can perpetuate or exacerbate biases present in training data. This can lead to unfair treatment or discrimination against specific groups, particularly marginalized communities.\n",
      "   - **Implication**: Disparate impacts could result in inequalities in areas like hiring, lending, law enforcement, and healthcare.\n",
      "\n",
      "2. **Transparency and Explainability**:\n",
      "   - Many AI systems, particularly those using complex algorithms, operate as \"black boxes,\" making it difficult to understand their decision-making processes.\n",
      "   - **Implication**: Lack of transparency can erode trust and make it challenging for affected individuals to understand and challenge decisions made about them.\n",
      "\n",
      "3. **Accountability and Responsibility**:\n",
      "   - When AI systems make decisions, it can be unclear who is responsible for outcomes, especially if those outcomes are harmful.\n",
      "   - **Implication**: This ambiguity can evade critical scrutiny and diminish the accountability of organizations deploying AI.\n",
      "\n",
      "4. **Privacy Concerns**:\n",
      "   - The use of AI often entails collecting and processing large amounts of personal data, raising concerns about privacy and consent.\n",
      "   - **Implication**: People may not have a clear understanding of how their data is used, leading to potential misuse or unauthorized access to personal information.\n",
      "\n",
      "5. **Informed Consent**:\n",
      "   - In contexts like healthcare, patients must be adequately informed about how AI will be used in their treatment decisions, including possible risks and benefits.\n",
      "   - **Implication**: Failure to ensure informed consent undermines ethical principles of autonomy and respect for individuals.\n",
      "\n",
      "6. **Autonomy**:\n",
      "   - AI systems can influence decisions in ways that may reduce human agency, as individuals might rely overly on automated recommendations.\n",
      "   - **Implication**: This can lead to a loss of personal responsibility or critical thinking regarding important life decisions.\n",
      "\n",
      "### Ensuring Accountability:\n",
      "\n",
      "1. **Regulatory Frameworks**:\n",
      "   - Establish laws and guidelines that govern the use of AI in critical decision-making areas. These should address ethical use, data protection, and accountability for outcomes.\n",
      "\n",
      "2. **Transparency Requirements**:\n",
      "   - Mandate that organizations provide clear, accessible information about how AI systems operate, including the data they use and how decisions are made.\n",
      "\n",
      "3. **Bias Mitigation Strategies**:\n",
      "   - Implement regular audits of AI systems to identify and rectify biases. This should include diverse training datasets and inclusive design practices to ensure fairness.\n",
      "\n",
      "4. **Human Oversight**:\n",
      "   - Maintain human-in-the-loop mechanisms where human judgment is involved in decision-making processes, especially in high-stakes scenarios such as criminal justice or medical diagnosis.\n",
      "\n",
      "5. **Clear Accountability Structures**:\n",
      "   - Define clear lines of accountability for AI-related decisions, ensuring that both developers and users of AI systems are responsible for the impacts of those systems.\n",
      "\n",
      "6. **Public Engagement and Stakeholder Involvement**:\n",
      "   - Involve diverse stakeholders, including impacted communities, in the design and implementation of AI systems to ensure that various perspectives are considered.\n",
      "\n",
      "7. **Ethical AI Frameworks**:\n",
      "   - Encourage the adoption of ethical frameworks by organizations that use AI, guiding their practices in alignment with social values and human rights.\n",
      "\n",
      "8. **Ongoing Education and Awareness**:\n",
      "   - Facilitate ongoing training for developers and users about the ethical implications of AI, emphasizing the importance of accountability and responsible usage.\n",
      "\n",
      "By attending to these ethical considerations and implementing strategies for accountability, we can strive to harness the benefits of AI while mitigating its risks and ensuring that it serves humanity equitably and responsibly.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "The increasing use of artificial intelligence (AI) in decision-making processes that affect human lives raises significant ethical concerns. Some of the key implications include:\n",
      "\n",
      "1. Bias and discrimination: AI systems can perpetuate existing biases and discriminatory practices if they are trained on biased data or designed with biased algorithms.\n",
      "2. Lack of transparency: Complex AI systems can be difficult to understand, making it challenging to identify mistakes or biases in decision-making processes.\n",
      "3. Autonomy and agency: As AI assumes more decision-making roles, there is a risk that humans may lose control over their own lives and decisions.\n",
      "4. Accountability: With AI involved in decision-making processes, it can be unclear who is responsible for errors or harm caused by those decisions.\n",
      "5. Value alignment: AI systems may not share human values, leading to decisions that are morally questionable.\n",
      "\n",
      "To ensure accountability in AI-based decision-making systems, consider the following measures:\n",
      "\n",
      "1. **Transparency and explainability**: Design AI systems that provide clear explanations for their decisions and actions, enabling humans to understand the reasoning behind those decisions.\n",
      "2. **Data quality and validation**: Ensure that training data is diverse\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(competitors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the ethical implications of employing artificial intelligence in decision-making processes that affect human lives, and how can we ensure accountability in such systems?\n"
     ]
    }
   ],
   "source": [
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Response from competitor 1\n",
      "\n",
      "The deployment of artificial intelligence (AI) in decision-making processes that affect human lives raises several ethical implications and concerns. These issues span multiple domains, including fairness, transparency, accountability, and privacy. Here are the key ethical implications and ways to ensure accountability:\n",
      "\n",
      "### Ethical Implications:\n",
      "\n",
      "1. **Bias and Discrimination**:\n",
      "   - AI systems can perpetuate or exacerbate biases present in training data. This can lead to unfair treatment or discrimination against specific groups, particularly marginalized communities.\n",
      "   - **Implication**: Disparate impacts could result in inequalities in areas like hiring, lending, law enforcement, and healthcare.\n",
      "\n",
      "2. **Transparency and Explainability**:\n",
      "   - Many AI systems, particularly those using complex algorithms, operate as \"black boxes,\" making it difficult to understand their decision-making processes.\n",
      "   - **Implication**: Lack of transparency can erode trust and make it challenging for affected individuals to understand and challenge decisions made about them.\n",
      "\n",
      "3. **Accountability and Responsibility**:\n",
      "   - When AI systems make decisions, it can be unclear who is responsible for outcomes, especially if those outcomes are harmful.\n",
      "   - **Implication**: This ambiguity can evade critical scrutiny and diminish the accountability of organizations deploying AI.\n",
      "\n",
      "4. **Privacy Concerns**:\n",
      "   - The use of AI often entails collecting and processing large amounts of personal data, raising concerns about privacy and consent.\n",
      "   - **Implication**: People may not have a clear understanding of how their data is used, leading to potential misuse or unauthorized access to personal information.\n",
      "\n",
      "5. **Informed Consent**:\n",
      "   - In contexts like healthcare, patients must be adequately informed about how AI will be used in their treatment decisions, including possible risks and benefits.\n",
      "   - **Implication**: Failure to ensure informed consent undermines ethical principles of autonomy and respect for individuals.\n",
      "\n",
      "6. **Autonomy**:\n",
      "   - AI systems can influence decisions in ways that may reduce human agency, as individuals might rely overly on automated recommendations.\n",
      "   - **Implication**: This can lead to a loss of personal responsibility or critical thinking regarding important life decisions.\n",
      "\n",
      "### Ensuring Accountability:\n",
      "\n",
      "1. **Regulatory Frameworks**:\n",
      "   - Establish laws and guidelines that govern the use of AI in critical decision-making areas. These should address ethical use, data protection, and accountability for outcomes.\n",
      "\n",
      "2. **Transparency Requirements**:\n",
      "   - Mandate that organizations provide clear, accessible information about how AI systems operate, including the data they use and how decisions are made.\n",
      "\n",
      "3. **Bias Mitigation Strategies**:\n",
      "   - Implement regular audits of AI systems to identify and rectify biases. This should include diverse training datasets and inclusive design practices to ensure fairness.\n",
      "\n",
      "4. **Human Oversight**:\n",
      "   - Maintain human-in-the-loop mechanisms where human judgment is involved in decision-making processes, especially in high-stakes scenarios such as criminal justice or medical diagnosis.\n",
      "\n",
      "5. **Clear Accountability Structures**:\n",
      "   - Define clear lines of accountability for AI-related decisions, ensuring that both developers and users of AI systems are responsible for the impacts of those systems.\n",
      "\n",
      "6. **Public Engagement and Stakeholder Involvement**:\n",
      "   - Involve diverse stakeholders, including impacted communities, in the design and implementation of AI systems to ensure that various perspectives are considered.\n",
      "\n",
      "7. **Ethical AI Frameworks**:\n",
      "   - Encourage the adoption of ethical frameworks by organizations that use AI, guiding their practices in alignment with social values and human rights.\n",
      "\n",
      "8. **Ongoing Education and Awareness**:\n",
      "   - Facilitate ongoing training for developers and users about the ethical implications of AI, emphasizing the importance of accountability and responsible usage.\n",
      "\n",
      "By attending to these ethical considerations and implementing strategies for accountability, we can strive to harness the benefits of AI while mitigating its risks and ensuring that it serves humanity equitably and responsibly.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "The increasing use of artificial intelligence (AI) in decision-making processes that affect human lives raises significant ethical concerns. Some of the key implications include:\n",
      "\n",
      "1. Bias and discrimination: AI systems can perpetuate existing biases and discriminatory practices if they are trained on biased data or designed with biased algorithms.\n",
      "2. Lack of transparency: Complex AI systems can be difficult to understand, making it challenging to identify mistakes or biases in decision-making processes.\n",
      "3. Autonomy and agency: As AI assumes more decision-making roles, there is a risk that humans may lose control over their own lives and decisions.\n",
      "4. Accountability: With AI involved in decision-making processes, it can be unclear who is responsible for errors or harm caused by those decisions.\n",
      "5. Value alignment: AI systems may not share human values, leading to decisions that are morally questionable.\n",
      "\n",
      "To ensure accountability in AI-based decision-making systems, consider the following measures:\n",
      "\n",
      "1. **Transparency and explainability**: Design AI systems that provide clear explanations for their decisions and actions, enabling humans to understand the reasoning behind those decisions.\n",
      "2. **Data quality and validation**: Ensure that training data is diverse\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = f\"\"\"You are judging a competition between {len(competitors)} competitors.\n",
    "Each model has been given this question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
    "Respond with JSON, and only JSON, with the following format:\n",
    "{{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}}\n",
    "\n",
    "Here are the responses from each competitor:\n",
    "\n",
    "{together}\n",
    "\n",
    "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are judging a competition between 2 competitors.\n",
      "Each model has been given this question:\n",
      "\n",
      "What are the ethical implications of employing artificial intelligence in decision-making processes that affect human lives, and how can we ensure accountability in such systems?\n",
      "\n",
      "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
      "Respond with JSON, and only JSON, with the following format:\n",
      "{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}\n",
      "\n",
      "Here are the responses from each competitor:\n",
      "\n",
      "# Response from competitor 1\n",
      "\n",
      "The deployment of artificial intelligence (AI) in decision-making processes that affect human lives raises several ethical implications and concerns. These issues span multiple domains, including fairness, transparency, accountability, and privacy. Here are the key ethical implications and ways to ensure accountability:\n",
      "\n",
      "### Ethical Implications:\n",
      "\n",
      "1. **Bias and Discrimination**:\n",
      "   - AI systems can perpetuate or exacerbate biases present in training data. This can lead to unfair treatment or discrimination against specific groups, particularly marginalized communities.\n",
      "   - **Implication**: Disparate impacts could result in inequalities in areas like hiring, lending, law enforcement, and healthcare.\n",
      "\n",
      "2. **Transparency and Explainability**:\n",
      "   - Many AI systems, particularly those using complex algorithms, operate as \"black boxes,\" making it difficult to understand their decision-making processes.\n",
      "   - **Implication**: Lack of transparency can erode trust and make it challenging for affected individuals to understand and challenge decisions made about them.\n",
      "\n",
      "3. **Accountability and Responsibility**:\n",
      "   - When AI systems make decisions, it can be unclear who is responsible for outcomes, especially if those outcomes are harmful.\n",
      "   - **Implication**: This ambiguity can evade critical scrutiny and diminish the accountability of organizations deploying AI.\n",
      "\n",
      "4. **Privacy Concerns**:\n",
      "   - The use of AI often entails collecting and processing large amounts of personal data, raising concerns about privacy and consent.\n",
      "   - **Implication**: People may not have a clear understanding of how their data is used, leading to potential misuse or unauthorized access to personal information.\n",
      "\n",
      "5. **Informed Consent**:\n",
      "   - In contexts like healthcare, patients must be adequately informed about how AI will be used in their treatment decisions, including possible risks and benefits.\n",
      "   - **Implication**: Failure to ensure informed consent undermines ethical principles of autonomy and respect for individuals.\n",
      "\n",
      "6. **Autonomy**:\n",
      "   - AI systems can influence decisions in ways that may reduce human agency, as individuals might rely overly on automated recommendations.\n",
      "   - **Implication**: This can lead to a loss of personal responsibility or critical thinking regarding important life decisions.\n",
      "\n",
      "### Ensuring Accountability:\n",
      "\n",
      "1. **Regulatory Frameworks**:\n",
      "   - Establish laws and guidelines that govern the use of AI in critical decision-making areas. These should address ethical use, data protection, and accountability for outcomes.\n",
      "\n",
      "2. **Transparency Requirements**:\n",
      "   - Mandate that organizations provide clear, accessible information about how AI systems operate, including the data they use and how decisions are made.\n",
      "\n",
      "3. **Bias Mitigation Strategies**:\n",
      "   - Implement regular audits of AI systems to identify and rectify biases. This should include diverse training datasets and inclusive design practices to ensure fairness.\n",
      "\n",
      "4. **Human Oversight**:\n",
      "   - Maintain human-in-the-loop mechanisms where human judgment is involved in decision-making processes, especially in high-stakes scenarios such as criminal justice or medical diagnosis.\n",
      "\n",
      "5. **Clear Accountability Structures**:\n",
      "   - Define clear lines of accountability for AI-related decisions, ensuring that both developers and users of AI systems are responsible for the impacts of those systems.\n",
      "\n",
      "6. **Public Engagement and Stakeholder Involvement**:\n",
      "   - Involve diverse stakeholders, including impacted communities, in the design and implementation of AI systems to ensure that various perspectives are considered.\n",
      "\n",
      "7. **Ethical AI Frameworks**:\n",
      "   - Encourage the adoption of ethical frameworks by organizations that use AI, guiding their practices in alignment with social values and human rights.\n",
      "\n",
      "8. **Ongoing Education and Awareness**:\n",
      "   - Facilitate ongoing training for developers and users about the ethical implications of AI, emphasizing the importance of accountability and responsible usage.\n",
      "\n",
      "By attending to these ethical considerations and implementing strategies for accountability, we can strive to harness the benefits of AI while mitigating its risks and ensuring that it serves humanity equitably and responsibly.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "The increasing use of artificial intelligence (AI) in decision-making processes that affect human lives raises significant ethical concerns. Some of the key implications include:\n",
      "\n",
      "1. Bias and discrimination: AI systems can perpetuate existing biases and discriminatory practices if they are trained on biased data or designed with biased algorithms.\n",
      "2. Lack of transparency: Complex AI systems can be difficult to understand, making it challenging to identify mistakes or biases in decision-making processes.\n",
      "3. Autonomy and agency: As AI assumes more decision-making roles, there is a risk that humans may lose control over their own lives and decisions.\n",
      "4. Accountability: With AI involved in decision-making processes, it can be unclear who is responsible for errors or harm caused by those decisions.\n",
      "5. Value alignment: AI systems may not share human values, leading to decisions that are morally questionable.\n",
      "\n",
      "To ensure accountability in AI-based decision-making systems, consider the following measures:\n",
      "\n",
      "1. **Transparency and explainability**: Design AI systems that provide clear explanations for their decisions and actions, enabling humans to understand the reasoning behind those decisions.\n",
      "2. **Data quality and validation**: Ensure that training data is diverse\n",
      "\n",
      "\n",
      "\n",
      "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\n"
     ]
    }
   ],
   "source": [
    "print(judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_messages = [{\"role\" : \"user\", \"content\" : judge}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"results\": [\"1\", \"2\"]}\n"
     ]
    }
   ],
   "source": [
    "# Judgement time!\n",
    "\n",
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(model = \"o3-mini\", messages = judge_messages)\n",
    "\n",
    "results = response.choices[0].message.content\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1 : gpt-4o-mini\n",
      "Rank 2 : llama3.2\n"
     ]
    }
   ],
   "source": [
    "# OK let's turn this into results!\n",
    "\n",
    "results_dict = json.loads(results)\n",
    "ranks = results_dict[\"results\"]\n",
    "for index, result in enumerate(ranks):\n",
    "    competitor = competitors[int(result) - 1]\n",
    "    print(f\"Rank {index + 1} : {competitor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Which pattern(s) did this use? Try updating this to add another Agentic design pattern.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Commercial implications</h2>\n",
    "            <span style=\"color:#00bfff;\">These kinds of patterns - to send a task to multiple models, and evaluate results,\n",
    "            are common where you need to improve the quality of your LLM response. This approach can be universally applied\n",
    "            to business projects where accuracy is critical.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
