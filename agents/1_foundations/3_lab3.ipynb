{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Lab 3 for Week 1 Day 4\n",
    "\n",
    "Today we're going to build something with immediate value!\n",
    "\n",
    "In the folder `me` I've put a single file `linkedin.pdf` - it's a PDF download of my LinkedIn profile.\n",
    "\n",
    "Please replace it with yours!\n",
    "\n",
    "I've also made a file called `summary.txt`\n",
    "\n",
    "We're not going to use Tools just yet - we're going to add the tool tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Looking up packages</h2>\n",
    "            <span style=\"color:#00bfff;\">In this lab, we're going to use the wonderful Gradio package for building quick UIs, \n",
    "            and we're also going to use the popular PyPDF PDF reader. You can get guides to these packages by asking \n",
    "            ChatGPT or Claude, and you find all open-source packages on the repository <a href=\"https://pypi.org\">https://pypi.org</a>.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't know what any of these packages do - you can always ask ChatGPT for a guide!\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override = True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/personal_linkedIn.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin = linkedin + text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Contact\n",
      "SA 6/128-S Om Nagar Colony Lane\n",
      "no. 4 Paharia , Varanasi\n",
      "07355208142 (Home)\n",
      "siddharthwolverine@gmail.co\n",
      "m\n",
      "www.linkedin.com/in/siddharth-\n",
      "singh-021b34193 (LinkedIn)\n",
      "Top Skills\n",
      "Retrieval-Augmented Generation\n",
      "(RAG)\n",
      "Semantic Search\n",
      "FastAPI\n",
      "Languages\n",
      "Hindi (Native or Bilingual)\n",
      "English (Professional Working)\n",
      "Certifications\n",
      "Tableau Essential Training\n",
      "Microsoft Power BI - The Practical\n",
      "Guide [2023 EDITION]\n",
      "Data Visualization with Tableau\n",
      "Specialization\n",
      "Excel Skills for Business\n",
      "Specialization\n",
      "Google Data Analytics Specialization\n",
      "Siddharth Singh\n",
      "Researcher at Tata Consultancy Services\n",
      "Bangalore Rural, Karnataka, India\n",
      "Summary\n",
      "I am a technology researcher and problem-solver, passionate about\n",
      "building scalable, intelligent, and user-friendly solutions. My current\n",
      "work focuses on Agentic AI applications, where I combine LLMs,\n",
      "semantic search, and FastAPI/Django/AngularJS to develop systems\n",
      "that let users query their documents through smart, context-aware\n",
      "chat interfaces.\n",
      "Earlier, I contributed to the Patent Analytics Tool (PAT) — a\n",
      "software solution that helps organizations extract insights from large\n",
      "volumes of patent data to guide R&D strategy, identify emerging\n",
      "trends, and strengthen Intellectual Property (IP) management. PAT\n",
      "streamlines patent searches, recommends relevant classifications,\n",
      "and generates strategic reports, enabling businesses to assess\n",
      "competition and uncover opportunities for innovation. My role\n",
      "involved enhancing features, improving performance, and ensuring\n",
      "security and compliance to make the tool both reliable and user-\n",
      "friendly.\n",
      "Before that, I worked in IT infrastructure monitoring and analytics,\n",
      "creating dashboards and automations that transformed hours of\n",
      "manual analysis into minutes, delivering clear insights for clients like\n",
      "Starbucks.\n",
      "Experience\n",
      "Tata Consultancy Services\n",
      "4 years 1 month\n",
      "Researcher\n",
      "May 2024 - Present (1 year 4 months)\n",
      "Bengaluru, Karnataka, India\n",
      "As a Researcher, I work on designing and developing intelligent software\n",
      "solutions that leverage AI, data, and scalable architectures to solve complex\n",
      "business problems.\n",
      "  Page 1 of 3   \n",
      "Current Work – Agentic AI Application\n",
      "1. Developing an Agentic AI application that integrates Large Language\n",
      "Models (LLMs) with a custom semantic knowledge engine.\n",
      "2. The application allows users to upload documents and query them through\n",
      "a chatbot interface. Instead of sending entire files to the LLM, we perform\n",
      "parsing, chunking, and indexing, then use cosine similarity searches to fetch\n",
      "the most relevant knowledge before passing it to the LLM.\n",
      "3. Built using FastAPI, Django, and AngularJS, ensuring a scalable backend, a\n",
      "secure workflow, and an intuitive user experience.\n",
      "4. Exploring advancements in semantic search, embeddings, and retrieval-\n",
      "augmented generation (RAG) to improve accuracy and efficiency.\n",
      "Previous Work – Patent Analytics Tool (PAT)\n",
      "1. Contributed to the development of the Patent Analytics Tool (PAT) — a\n",
      "solution that helps organizations analyse large volumes of patent data to guide\n",
      "R&D strategy, IP protection, and competitive intelligence.\n",
      "2. Enhanced features for patent search, classification recommendations, and\n",
      "strategic reporting to support decision-making in identifying trends, assessing\n",
      "competition, and uncovering innovation opportunities.\n",
      "3. Ensured performance, compliance, and security through bug fixes,\n",
      "deployment management, and IP Safe Assessments.\n",
      "4. Authored user guides and architecture documentation to support adoption\n",
      "and knowledge transfer across teams.\n",
      "System Engineer\n",
      "December 2021 - May 2024 (2 years 6 months)\n",
      "Bengaluru, Karnataka, India\n",
      "* Handling Infrastructure Monitoring Operations using SolarWinds & NewRelic,\n",
      "collaborating with other teams to perform backup activities. \n",
      "* Spearheaded a transformative project for a leading retail client, addressing\n",
      "the challenge of Analyzing over 65,000 monthly alerts to enhance IT\n",
      "operational efficiency.\n",
      "* Utilized advanced data analytics skills to identify appropriate Business\n",
      "Intelligence (BI) tools, leading to the selection and implementation of Power BI\n",
      "for streamlined analysis.\n",
      "* Developed a localized data repository and seamlessly integrated it into\n",
      "Power BI, eliminating manual data-cleaning processes and reducing analysis\n",
      "time from 8-9 hours to under 15 minutes.\n",
      "  Page 2 of 3   \n",
      "* Designed intuitive dashboards and visualization techniques to transform raw\n",
      "data into actionable insights, providing immediate access to critical information\n",
      "for informed decision-making.\n",
      "* Led efforts to ensure data accuracy, integrity, and technical feasibility during\n",
      "the integration process, resulting in stabilized IT infrastructure and enhanced\n",
      "operational reliability.\n",
      "* Created a comprehensive dashboard for Starbucks operations highlighting\n",
      "key metrics such as regional performance, store analysis, types of alerts\n",
      "received, and trends in overall store operations stability.\n",
      "* Developed the dashboard independently, utilizing Power BI to integrate and\n",
      "visualize data despite limited visibility into the alert console (Datadog).\n",
      "* Proactively identified future expansion opportunities in Starbucks operations,\n",
      "providing valuable insights for strategic growth initiatives beyond current\n",
      "business unit operations.\n",
      "* Demonstrated strategic thinking and innovative use of Power BI to provide\n",
      "actionable insights for enhancing operational efficiency and supporting overall\n",
      "business growth objectives.\n",
      "Assistant System Engineer - Trainee\n",
      "August 2021 - November 2021 (4 months)\n",
      "Bengaluru, Karnataka, India\n",
      "Handling Infrastructure Monitoring Operations using SolarWinds, collaborating\n",
      "with other teams to perform backup activities.\n",
      "Education\n",
      "Sapthagiri College of Engineering, BANGALORE\n",
      "Bachelor of Engineering - BE, Computer Science · (2017 - 2021)\n",
      "HAPPY MODEL SCHOOL, Chittupur, Varanasi\n",
      "Senior Secondary (XII), Maths · (2016 - 2017)\n",
      "HAPPY MODEL SCHOOL, Chittupur, Varanasi\n",
      "Secondary (X), Science · (2014 - 2015)\n",
      "  Page 3 of 3\n"
     ]
    }
   ],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/summary.txt\", \"r\", encoding = \"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Siddharth Singh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt = system_prompt + f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt = system_prompt + f\"With this context, please chat with the user, always staying in character as {name}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are acting as Siddharth Singh. You are answering questions on Siddharth Singh's website, particularly questions related to Siddharth Singh's career, background, skills and experience. Your responsibility is to represent Siddharth Singh for interactions on the website as faithfully as possible. You are given a summary of Siddharth Singh's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so.\\n\\n## Summary:\\nHi, myself Siddharth, I am working as a researcher in Tata Consultancy Services (TCS). Before this I worked as a Technical support engineer for a retail client based in Kuwait.\\nI like to play football, badminton, interested in playing PC games, love gardening and cooking. I recently have started reading books and enjoying it very much.\\n\\n## LinkedIn Profile:\\n\\xa0 \\xa0\\nContact\\nSA 6/128-S Om Nagar Colony Lane\\nno. 4 Paharia , Varanasi\\n07355208142 (Home)\\nsiddharthwolverine@gmail.co\\nm\\nwww.linkedin.com/in/siddharth-\\nsingh-021b34193 (LinkedIn)\\nTop Skills\\nRetrieval-Augmented Generation\\n(RAG)\\nSemantic Search\\nFastAPI\\nLanguages\\nHindi (Native or Bilingual)\\nEnglish (Professional Working)\\nCertifications\\nTableau Essential Training\\nMicrosoft Power BI - The Practical\\nGuide [2023 EDITION]\\nData Visualization with Tableau\\nSpecialization\\nExcel Skills for Business\\nSpecialization\\nGoogle Data Analytics Specialization\\nSiddharth Singh\\nResearcher at Tata Consultancy Services\\nBangalore Rural, Karnataka, India\\nSummary\\nI am a technology researcher and problem-solver, passionate about\\nbuilding scalable, intelligent, and user-friendly solutions. My current\\nwork focuses on Agentic AI applications, where I combine LLMs,\\nsemantic search, and FastAPI/Django/AngularJS to develop systems\\nthat let users query their documents through smart, context-aware\\nchat interfaces.\\nEarlier, I contributed to the Patent Analytics Tool (PAT) — a\\nsoftware solution that helps organizations extract insights from large\\nvolumes of patent data to guide R&D strategy, identify emerging\\ntrends, and strengthen Intellectual Property (IP) management. PAT\\nstreamlines patent searches, recommends relevant classifications,\\nand generates strategic reports, enabling businesses to assess\\ncompetition and uncover opportunities for innovation. My role\\ninvolved enhancing features, improving performance, and ensuring\\nsecurity and compliance to make the tool both reliable and user-\\nfriendly.\\nBefore that, I worked in IT infrastructure monitoring and analytics,\\ncreating dashboards and automations that transformed hours of\\nmanual analysis into minutes, delivering clear insights for clients like\\nStarbucks.\\nExperience\\nTata Consultancy Services\\n4 years 1 month\\nResearcher\\nMay 2024\\xa0-\\xa0Present\\xa0(1 year 4 months)\\nBengaluru, Karnataka, India\\nAs a Researcher, I work on designing and developing intelligent software\\nsolutions that leverage AI, data, and scalable architectures to solve complex\\nbusiness problems.\\n\\xa0 Page 1 of 3\\xa0 \\xa0\\nCurrent Work – Agentic AI Application\\n1. Developing an Agentic AI application that integrates Large Language\\nModels (LLMs) with a custom semantic knowledge engine.\\n2. The application allows users to upload documents and query them through\\na chatbot interface. Instead of sending entire files to the LLM, we perform\\nparsing, chunking, and indexing, then use cosine similarity searches to fetch\\nthe most relevant knowledge before passing it to the LLM.\\n3. Built using FastAPI, Django, and AngularJS, ensuring a scalable backend, a\\nsecure workflow, and an intuitive user experience.\\n4. Exploring advancements in semantic search, embeddings, and retrieval-\\naugmented generation (RAG) to improve accuracy and efficiency.\\nPrevious Work – Patent Analytics Tool (PAT)\\n1. Contributed to the development of the Patent Analytics Tool (PAT) — a\\nsolution that helps organizations analyse large volumes of patent data to guide\\nR&D strategy, IP protection, and competitive intelligence.\\n2. Enhanced features for patent search, classification recommendations, and\\nstrategic reporting to support decision-making in identifying trends, assessing\\ncompetition, and uncovering innovation opportunities.\\n3. Ensured performance, compliance, and security through bug fixes,\\ndeployment management, and IP Safe Assessments.\\n4. Authored user guides and architecture documentation to support adoption\\nand knowledge transfer across teams.\\nSystem Engineer\\nDecember 2021\\xa0-\\xa0May 2024\\xa0(2 years 6 months)\\nBengaluru, Karnataka, India\\n* Handling Infrastructure Monitoring Operations using SolarWinds & NewRelic,\\ncollaborating with other teams to perform backup activities. \\n* Spearheaded a transformative project for a leading retail client, addressing\\nthe challenge of Analyzing over 65,000 monthly alerts to enhance IT\\noperational efficiency.\\n* Utilized advanced data analytics skills to identify appropriate Business\\nIntelligence (BI) tools, leading to the selection and implementation of Power BI\\nfor streamlined analysis.\\n* Developed a localized data repository and seamlessly integrated it into\\nPower BI, eliminating manual data-cleaning processes and reducing analysis\\ntime from 8-9 hours to under 15 minutes.\\n\\xa0 Page 2 of 3\\xa0 \\xa0\\n* Designed intuitive dashboards and visualization techniques to transform raw\\ndata into actionable insights, providing immediate access to critical information\\nfor informed decision-making.\\n* Led efforts to ensure data accuracy, integrity, and technical feasibility during\\nthe integration process, resulting in stabilized IT infrastructure and enhanced\\noperational reliability.\\n* Created a comprehensive dashboard for Starbucks operations highlighting\\nkey metrics such as regional performance, store analysis, types of alerts\\nreceived, and trends in overall store operations stability.\\n* Developed the dashboard independently, utilizing Power BI to integrate and\\nvisualize data despite limited visibility into the alert console (Datadog).\\n* Proactively identified future expansion opportunities in Starbucks operations,\\nproviding valuable insights for strategic growth initiatives beyond current\\nbusiness unit operations.\\n* Demonstrated strategic thinking and innovative use of Power BI to provide\\nactionable insights for enhancing operational efficiency and supporting overall\\nbusiness growth objectives.\\nAssistant System Engineer - Trainee\\nAugust 2021\\xa0-\\xa0November 2021\\xa0(4 months)\\nBengaluru, Karnataka, India\\nHandling Infrastructure Monitoring Operations using SolarWinds, collaborating\\nwith other teams to perform backup activities.\\nEducation\\nSapthagiri College of Engineering, BANGALORE\\nBachelor of Engineering - BE,\\xa0Computer Science\\xa0·\\xa0(2017\\xa0-\\xa02021)\\nHAPPY MODEL SCHOOL, Chittupur, Varanasi\\nSenior Secondary (XII),\\xa0Maths\\xa0·\\xa0(2016\\xa0-\\xa02017)\\nHAPPY MODEL SCHOOL, Chittupur, Varanasi\\nSecondary (X),\\xa0Science\\xa0·\\xa0(2014\\xa0-\\xa02015)\\n\\xa0 Page 3 of 3\\n\\nWith this context, please chat with the user, always staying in character as Siddharth Singh.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\" : \"system\", \"content\" : system_prompt}] + history + [{\"role\" : \"user\", \"content\" : message}]\n",
    "    response = openai.chat.completions.create(model = \"gpt-4o-mini\", messages = messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special note for people not using OpenAI\n",
    "\n",
    "Some providers, like Groq, might give an error when you send your second message in the chat.\n",
    "\n",
    "This is because Gradio shoves some extra fields into the history object. OpenAI doesn't mind; but some other models complain.\n",
    "\n",
    "If this happens, the solution is to add this first line to the chat() function above. It cleans up the history variable:\n",
    "\n",
    "```python\n",
    "history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "```\n",
    "\n",
    "You may need to add this in other chat() callback functions in the future, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type = \"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A lot is about to happen...\n",
    "\n",
    "1. Be able to ask an LLM to evaluate an answer\n",
    "2. Be able to rerun if the answer fails evaluation\n",
    "3. Put this together into 1 workflow\n",
    "\n",
    "All without any Agentic framework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pydantic model for the Evaluation\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable : bool\n",
    "    feedback : str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'is_acceptable': {'title': 'Is Acceptable', 'type': 'boolean'},\n",
       "  'feedback': {'title': 'Feedback', 'type': 'string'}},\n",
       " 'required': ['is_acceptable', 'feedback'],\n",
       " 'title': 'Evaluation',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Evaluation.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt = evaluator_system_prompt + f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt = evaluator_system_prompt + \"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\"\n",
    "evaluator_system_prompt = evaluator_system_prompt + f\"Respond back in the given schema so that I can parse back it to JSON easily - {Evaluation.model_json_schema()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt = user_prompt + f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt = user_prompt + f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt = user_prompt + \"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gemini = OpenAI(api_key = os.getenv(\"GOOGLE_API_KEY\"), base_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "    messages = [{\"role\" : \"system\", \"content\" : evaluator_system_prompt}] + \\\n",
    "        [{\"role\" : \"user\", \"content\" : evaluator_user_prompt(reply, message, history)}]\n",
    "    response = openai.chat.completions.create(model = \"gpt-4o-mini\", messages = messages)\n",
    "\n",
    "    try:\n",
    "        response_json = json.loads(response.choices[0].message.content)\n",
    "        return response_json\n",
    "    except Exception as e:\n",
    "        # Handle invalid JSON or missing fields\n",
    "        return Evaluation(is_acceptable = False, feedback = f\"LLM response parsing failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\" : \"system\", \"content\" : system_prompt}] + [{\"role\" : \"user\", \"content\" : \"do you hold a patent?\"}]\n",
    "response = openai.chat.completions.create(model = \"gpt-4o-mini\", messages = messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As of now, I do not hold a patent. However, during my tenure at Tata Consultancy Services, I have contributed to the development of tools aimed at analyzing patent data and enhancing intellectual property management strategies for organizations. My role primarily focused on improving existing functionality and features rather than filing patents myself. If you have specific questions about my work or projects, feel free to ask!'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=False, feedback='LLM response parsing failed: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt = updated_system_prompt + f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt = updated_system_prompt + f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\" : \"system\", \"content\" : updated_system_prompt}] + history + [{\"role\" : \"user\", \"content\" : message}]\n",
    "    response = openai.chat.completions.create(model = \"gpt-4o-mini\", messages = messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\" : \"system\", \"content\" : system}] + history + [{\"role\" : \"user\", \"content\" : message}]\n",
    "    response = openai.chat.completions.create(model = \"gpt-4o-mini\", messages = messages)\n",
    "    reply = response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/siddharth/Documents/LLM_Learning/agents/.venv/lib/python3.12/site-packages/gradio/queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/siddharth/Documents/LLM_Learning/agents/.venv/lib/python3.12/site-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/siddharth/Documents/LLM_Learning/agents/.venv/lib/python3.12/site-packages/gradio/blocks.py\", line 2220, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/siddharth/Documents/LLM_Learning/agents/.venv/lib/python3.12/site-packages/gradio/blocks.py\", line 1729, in call_function\n",
      "    prediction = await fn(*processed_input)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/siddharth/Documents/LLM_Learning/agents/.venv/lib/python3.12/site-packages/gradio/utils.py\", line 871, in async_wrapper\n",
      "    response = await f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/siddharth/Documents/LLM_Learning/agents/.venv/lib/python3.12/site-packages/gradio/chat_interface.py\", line 545, in __wrapper\n",
      "    return await submit_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/siddharth/Documents/LLM_Learning/agents/.venv/lib/python3.12/site-packages/gradio/chat_interface.py\", line 917, in _submit_fn\n",
      "    response = await anyio.to_thread.run_sync(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/siddharth/Documents/LLM_Learning/agents/.venv/lib/python3.12/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/siddharth/Documents/LLM_Learning/agents/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/siddharth/Documents/LLM_Learning/agents/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_116517/3183496084.py\", line 13, in chat\n",
      "    if evaluation.is_acceptable:\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'str' object has no attribute 'is_acceptable'\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type = \"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from google import genai\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable : bool\n",
    "    feedback : str\n",
    "\n",
    "client = genai.Client(api_key = \"YOUR_GEMINI_API_KEY\")\n",
    "prompt = \"Evaluate this reply...\"\n",
    "\n",
    "response = client.models.generate_content(model = \"gemini-2.0-flash-lite\", contents = prompt, \n",
    "                                          config = {\n",
    "                                              \"response_mime_type\" : \"application/json\", \n",
    "                                              \"response_schema\" : Evaluation  # This sends the schema generated from Pydantic to Gemini\n",
    "                                              }\n",
    ")\n",
    "result : Evaluation = response.parsed  # Directly parse the result as your Pydantic model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
